{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eabb7f-266a-4b22-b16d-27ee12ea1a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:20<00:00,  5.18s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.1-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1592/1592 [00:02<00:00, 698.60 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 398/398 [00:00<00:00, 758.55 examples/s]\n",
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1036242/1700597310.py:160: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning_rate=0.001, weight_decay=0.01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1036242/1700597310.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmghasemizade97\u001b[0m (\u001b[33mmghasemizade97-university-of-vermont\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/u/mghasemizade/wandb/run-20241213_064932-nmbcz94o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mghasemizade97-university-of-vermont/huggingface/runs/nmbcz94o' target=\"_blank\">sequence_classification_lr0.001_wd0.01</a></strong> to <a href='https://wandb.ai/mghasemizade97-university-of-vermont/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mghasemizade97-university-of-vermont/huggingface' target=\"_blank\">https://wandb.ai/mghasemizade97-university-of-vermont/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mghasemizade97-university-of-vermont/huggingface/runs/nmbcz94o' target=\"_blank\">https://wandb.ai/mghasemizade97-university-of-vermont/huggingface/runs/nmbcz94o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 1:54:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.801300</td>\n",
       "      <td>1.192398</td>\n",
       "      <td>0.319400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.502100</td>\n",
       "      <td>0.720931</td>\n",
       "      <td>0.489979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.663513</td>\n",
       "      <td>0.616440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 02:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1036242/1700597310.py:160: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing test 887     2\n",
      "1670    3\n",
      "414     1\n",
      "1080    0\n",
      "1102    2\n",
      "       ..\n",
      "1753    0\n",
      "907     3\n",
      "261     0\n",
      "1403    3\n",
      "1543    1\n",
      "Name: Institutional_Form_category, Length: 398, dtype: int8 and pred 887     2\n",
      "1670    3\n",
      "414     3\n",
      "1080    0\n",
      "1102    2\n",
      "       ..\n",
      "1753    0\n",
      "907     3\n",
      "261     0\n",
      "1403    0\n",
      "1543    1\n",
      "Name: predictions, Length: 398, dtype: int64\n",
      "Confusion Matrix:\n",
      "[[ 61   1   6  19]\n",
      " [  3  55   1   3]\n",
      " [  2   1  51  10]\n",
      " [ 21   7   4 153]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70        87\n",
      "           1       0.86      0.89      0.87        62\n",
      "           2       0.82      0.80      0.81        64\n",
      "           3       0.83      0.83      0.83       185\n",
      "\n",
      "    accuracy                           0.80       398\n",
      "   macro avg       0.80      0.80      0.80       398\n",
      "weighted avg       0.80      0.80      0.80       398\n",
      "\n",
      "Balanced Accuracy Score: 0.8030370566269829\n",
      "Accuracy Score: 0.8040201005025126\n",
      "Results for learning_rate=0.001, weight_decay=0.01\n",
      "Train Loss: 0.9039071583747864\n",
      "Evaluation Metrics: {'eval_loss': 0.6635130047798157, 'eval_pearson': 0.6164403594309218, 'eval_runtime': 181.0595, 'eval_samples_per_second': 2.198, 'eval_steps_per_second': 0.039, 'epoch': 3.0}\n",
      "Performance Metrics: None\n",
      "\n",
      "Training with learning_rate=0.001, weight_decay=0.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1036242/1700597310.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 1:54:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.396400</td>\n",
       "      <td>0.903241</td>\n",
       "      <td>0.540523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.777591</td>\n",
       "      <td>0.613224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.726971</td>\n",
       "      <td>0.600256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 02:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1036242/1700597310.py:160: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing test 887     2\n",
      "1670    3\n",
      "414     1\n",
      "1080    0\n",
      "1102    2\n",
      "       ..\n",
      "1753    0\n",
      "907     3\n",
      "261     0\n",
      "1403    3\n",
      "1543    1\n",
      "Name: Institutional_Form_category, Length: 398, dtype: int8 and pred 887     2\n",
      "1670    3\n",
      "414     3\n",
      "1080    0\n",
      "1102    2\n",
      "       ..\n",
      "1753    0\n",
      "907     3\n",
      "261     0\n",
      "1403    3\n",
      "1543    1\n",
      "Name: predictions, Length: 398, dtype: int64\n",
      "Confusion Matrix:\n",
      "[[ 58   1   5  23]\n",
      " [  2  56   1   3]\n",
      " [  1   0  57   6]\n",
      " [ 21   4   6 154]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69        87\n",
      "           1       0.92      0.90      0.91        62\n",
      "           2       0.83      0.89      0.86        64\n",
      "           3       0.83      0.83      0.83       185\n",
      "\n",
      "    accuracy                           0.82       398\n",
      "   macro avg       0.82      0.82      0.82       398\n",
      "weighted avg       0.82      0.82      0.82       398\n",
      "\n",
      "Balanced Accuracy Score: 0.823237476387678\n",
      "Accuracy Score: 0.8165829145728644\n",
      "Results for learning_rate=0.001, weight_decay=0.1\n",
      "Train Loss: 0.1846812563141187\n",
      "Evaluation Metrics: {'eval_loss': 0.7269712090492249, 'eval_pearson': 0.6002556283756659, 'eval_runtime': 181.3012, 'eval_samples_per_second': 2.195, 'eval_steps_per_second': 0.039, 'epoch': 3.0}\n",
      "Performance Metrics: None\n",
      "\n",
      "Training with learning_rate=0.001, weight_decay=-0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1036242/1700597310.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9/75 09:58 < 1:34:00, 0.01 it/s, Epoch 0.32/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import functools\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import evaluate\n",
    "import re\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "df1 = pd.read_csv('filtered_labeled.csv')\n",
    "df2 = pd.read_csv('synthetic_data.csv')\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'(\\n[a-zA-Z])', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "df['Institutional_Form'] = df['Institutional_Form'].astype('category')\n",
    "df['Institutional_Form_category'] = df['Institutional_Form'].cat.codes\n",
    "category_map = {code: category for code, category in enumerate(df['Institutional_Form'].cat.categories)}\n",
    "\n",
    "df_train, df_val = train_test_split(df, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def generate_features_with_prompt(df):\n",
    "    # Define the instruction\n",
    "    instruction = (\n",
    "        \"You are a contract classification assistant. Your task is to classify the contract text \"\n",
    "        \"into one of the predefined categories. Here are the criteria for each category:\\n\"\n",
    "        \"- Joint Operations: Partnership arrangements to jointly produce services with one or more organizations.\\n\"\n",
    "        \"- New Joint Entities: Two or more organizations creating a separate new entity to manage or govern a shared asset or service.\\n\"\n",
    "        \"- Resource Sharing: Sharing of information, personnel, equipment, etc., between governments or community organizations to provide services.\\n\"\n",
    "        \"- Service Contracts: Agreements with outside entities, public or private, for provision or support services.\\n\"\n",
    "        \"Analyze the given text carefully and respond with the appropriate category.\"\n",
    "    )\n",
    "    df['Institutional_Form'] = df['Institutional_Form'].astype(str)\n",
    "    # Generate the `input` column by combining instruction, text, and category\n",
    "    df['input'] = (\n",
    "        instruction\n",
    "        + \"\\n\\nContract Text: \"\n",
    "        + df['text']\n",
    "        + \"\\n\\nInstitutional Form Category: \"\n",
    "        + df['Institutional_Form']\n",
    "    )\n",
    "\n",
    "    # Add the numerical category column if not already present\n",
    "    if 'Institutional_Form_category' not in df.columns:\n",
    "        df['Institutional_Form'] = df['Institutional_Form'].astype('category')\n",
    "        df['Institutional_Form_category'] = df['Institutional_Form'].cat.codes\n",
    "\n",
    "    return df\n",
    "\n",
    "generate_features_with_prompt(df_train)\n",
    "generate_features_with_prompt(df_val)\n",
    "\n",
    "dataset_train = Dataset.from_pandas(df_train.reset_index(drop=True))\n",
    "dataset_val = Dataset.from_pandas(df_val.reset_index(drop=True))\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset_train,\n",
    "    'val': dataset_val,\n",
    "})\n",
    "\n",
    "#Since our classes are not balanced let's calculate class weights based on inverse value counts\n",
    "#Convert to pytorch tensor since we will need it\n",
    "df_train.Institutional_Form_category.value_counts(normalize=True)\n",
    "class_weights=(1/df_train.Institutional_Form.value_counts(normalize=True).sort_index()).tolist()\n",
    "class_weights=torch.tensor(class_weights)\n",
    "class_weights=class_weights/class_weights.sum()\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "#Quantization Config (for QLORA)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, # enable 4-bit quantization\n",
    "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
    "    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    ")\n",
    "\n",
    "#\n",
    "lora_config = LoraConfig(\n",
    "    r = 16, # the dimension of the low-rank matrices\n",
    "    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "    lora_dropout = 0.05, # dropout probability of the LoRA layers\n",
    "    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
    "    task_type = 'SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=len(category_map)\n",
    ")\n",
    "\n",
    "#prepare_model_for_kbit_training() function to preprocess the quantized model for training.\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "#Must use .cache = False as below or it crashes from my experience\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "def llama_preprocessing_function(examples):\n",
    "    return tokenizer(examples['input'], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"Institutional_Form_category\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "#Purpose: Automatically pads text data to the longest sequence in a batch\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    try:\n",
    "        # it's a classification task, take the argmax\n",
    "        predictions_processed = np.argmax(predictions, axis=1)\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        pearson, _ = pearsonr(predictions_processed, labels)\n",
    "\n",
    "        return {'pearson': pearson}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_metrics: {e}\")\n",
    "        return {'pearson': None}\n",
    "    \n",
    "#We will have a custom loss function that deals with the class weights and have class weights as additional argument in constructor\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Ensure label_weights is a tensor\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
    "        # Extract labels and convert them to long type for cross_entropy\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract logits assuming they are directly outputted by the model\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Compute custom loss with class weights for imbalanced data handling\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "\n",
    "def make_predictions(model, df):\n",
    "    \n",
    "\n",
    "    sentences = df.input.tolist()\n",
    "\n",
    "      # Define the batch size\n",
    "    batch_size = 32  # You can adjust this based on your system's memory capacity\n",
    "\n",
    "      # Initialize an empty list to store the model outputs\n",
    "    all_outputs = []\n",
    "\n",
    "      # Process the sentences in batches\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "          # Get the batch of sentences\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "\n",
    "          # Tokenize the batch\n",
    "        inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "          # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
    "        inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "\n",
    "          # Perform inference and store the logits\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            all_outputs.append(outputs['logits'])\n",
    "\n",
    "    final_outputs = torch.cat(all_outputs, dim=0)\n",
    "    df['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
    "    #df['predictions']=df['predictions'].apply(lambda l:category_map[l])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "    \n",
    "def get_performance_metrics(df):\n",
    "    y_test = df.Institutional_Form_category\n",
    "    y_pred = df.predictions\n",
    "    print(f\"comparing test {y_test} and pred {y_pred}\")\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "# Define hyperparameter grid\n",
    "learning_rates = [1e-3]\n",
    "weight_decays = [0.01, 0.1, 0.2]\n",
    "\n",
    "# Keep track of results\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for wd in weight_decays:\n",
    "        print(f\"\\nTraining with learning_rate={lr}, weight_decay={wd}\\n\")\n",
    "\n",
    "        # Update training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f'sequence_classification_lr{lr}_wd{wd}',\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=16,\n",
    "            num_train_epochs=3,\n",
    "            weight_decay=wd,\n",
    "            evaluation_strategy='epoch',\n",
    "            save_strategy='epoch',\n",
    "            load_best_model_at_end=True,\n",
    "            logging_dir=f'logs_lr{lr}_wd{wd}',\n",
    "            logging_steps=10\n",
    "        )\n",
    "\n",
    "        # Initialize trainer\n",
    "        trainer = CustomTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_datasets['train'],\n",
    "            eval_dataset=tokenized_datasets['val'],\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=collate_fn,\n",
    "            compute_metrics=compute_metrics,\n",
    "            class_weights=class_weights,\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        train_result = trainer.train()\n",
    "\n",
    "        # Record training loss and evaluation metrics\n",
    "        eval_metrics = trainer.evaluate()\n",
    "        train_loss = train_result.training_loss\n",
    "\n",
    "        # Make predictions and compute performance metrics\n",
    "        df_val = make_predictions(model, df_val)\n",
    "        performance_metrics = get_performance_metrics(df_val)\n",
    "\n",
    "        # Append the metrics to results\n",
    "        results.append({\n",
    "            \"learning_rate\": lr,\n",
    "            \"weight_decay\": wd,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"eval_metrics\": eval_metrics,\n",
    "            \"performance_metrics\": performance_metrics\n",
    "        })\n",
    "\n",
    "        # Print results for the current model\n",
    "        print(f\"Results for learning_rate={lr}, weight_decay={wd}\")\n",
    "        print(f\"Train Loss: {train_loss}\")\n",
    "        print(f\"Evaluation Metrics: {eval_metrics}\")\n",
    "        print(f\"Performance Metrics: {performance_metrics}\")\n",
    "\n",
    "# Summarize all results\n",
    "print(\"\\nSummary of all results:\")\n",
    "for res in results:\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38745aca-a0b4-441a-b600-19cbe8c2ff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.34s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.1-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1592/1592 [00:02<00:00, 749.40 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 398/398 [00:00<00:00, 792.97 examples/s]\n",
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3072437/884210954.py:160: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/tmp/ipykernel_3072437/884210954.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning_rate=0.001, weight_decay=0.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/mghasemizade/miniconda3/envs/llama/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4/75 02:45 < 1:38:03, 0.01 it/s, Epoch 0.12/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 286\u001b[0m\n\u001b[1;32m    274\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(\n\u001b[1;32m    275\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    276\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m     class_weights\u001b[38;5;241m=\u001b[39mclass_weights,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m train_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# Record training loss and evaluation metrics\u001b[39;00m\n\u001b[1;32m    289\u001b[0m eval_metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.11/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2124\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2125\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2126\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2127\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2128\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.11/site-packages/transformers/trainer.py:2486\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import functools\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import evaluate\n",
    "import re\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "df1 = pd.read_csv('filtered_labeled.csv')\n",
    "df2 = pd.read_csv('synthetic_data.csv')\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'(\\n[a-zA-Z])', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "df['Institutional_Form'] = df['Institutional_Form'].astype('category')\n",
    "df['Institutional_Form_category'] = df['Institutional_Form'].cat.codes\n",
    "category_map = {code: category for code, category in enumerate(df['Institutional_Form'].cat.categories)}\n",
    "\n",
    "df_train, df_val = train_test_split(df, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def generate_features_with_prompt(df):\n",
    "    # Define the instruction\n",
    "    instruction = (\n",
    "        \"You are a contract classification assistant. Your task is to classify the contract text \"\n",
    "        \"into one of the predefined categories. Here are the criteria for each category:\\n\"\n",
    "        \"- Joint Operations: Partnership arrangements to jointly produce services with one or more organizations.\\n\"\n",
    "        \"- New Joint Entities: Two or more organizations creating a separate new entity to manage or govern a shared asset or service.\\n\"\n",
    "        \"- Resource Sharing: Sharing of information, personnel, equipment, etc., between governments or community organizations to provide services.\\n\"\n",
    "        \"- Service Contracts: Agreements with outside entities, public or private, for provision or support services.\\n\"\n",
    "        \"Analyze the given text carefully and respond with the appropriate category.\"\n",
    "    )\n",
    "    df['Institutional_Form'] = df['Institutional_Form'].astype(str)\n",
    "    # Generate the `input` column by combining instruction, text, and category\n",
    "    df['input'] = (\n",
    "        instruction\n",
    "        + \"\\n\\nContract Text: \"\n",
    "        + df['text']\n",
    "        + \"\\n\\nInstitutional Form Category: \"\n",
    "        + df['Institutional_Form']\n",
    "    )\n",
    "\n",
    "    # Add the numerical category column if not already present\n",
    "    if 'Institutional_Form_category' not in df.columns:\n",
    "        df['Institutional_Form'] = df['Institutional_Form'].astype('category')\n",
    "        df['Institutional_Form_category'] = df['Institutional_Form'].cat.codes\n",
    "\n",
    "    return df\n",
    "\n",
    "generate_features_with_prompt(df_train)\n",
    "generate_features_with_prompt(df_val)\n",
    "\n",
    "dataset_train = Dataset.from_pandas(df_train.reset_index(drop=True))\n",
    "dataset_val = Dataset.from_pandas(df_val.reset_index(drop=True))\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset_train,\n",
    "    'val': dataset_val,\n",
    "})\n",
    "\n",
    "#Since our classes are not balanced let's calculate class weights based on inverse value counts\n",
    "#Convert to pytorch tensor since we will need it\n",
    "df_train.Institutional_Form_category.value_counts(normalize=True)\n",
    "class_weights=(1/df_train.Institutional_Form.value_counts(normalize=True).sort_index()).tolist()\n",
    "class_weights=torch.tensor(class_weights)\n",
    "class_weights=class_weights/class_weights.sum()\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "#Quantization Config (for QLORA)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, # enable 4-bit quantization\n",
    "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
    "    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    ")\n",
    "\n",
    "#\n",
    "lora_config = LoraConfig(\n",
    "    r = 16, # the dimension of the low-rank matrices\n",
    "    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "    lora_dropout = 0.05, # dropout probability of the LoRA layers\n",
    "    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
    "    task_type = 'SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=len(category_map)\n",
    ")\n",
    "\n",
    "#prepare_model_for_kbit_training() function to preprocess the quantized model for training.\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "#Must use .cache = False as below or it crashes from my experience\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "def llama_preprocessing_function(examples):\n",
    "    return tokenizer(examples['input'], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"Institutional_Form_category\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "#Purpose: Automatically pads text data to the longest sequence in a batch\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    try:\n",
    "        # it's a classification task, take the argmax\n",
    "        predictions_processed = np.argmax(predictions, axis=1)\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        pearson, _ = pearsonr(predictions_processed, labels)\n",
    "\n",
    "        return {'pearson': pearson}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_metrics: {e}\")\n",
    "        return {'pearson': None}\n",
    "    \n",
    "#We will have a custom loss function that deals with the class weights and have class weights as additional argument in constructor\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Ensure label_weights is a tensor\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
    "        # Extract labels and convert them to long type for cross_entropy\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract logits assuming they are directly outputted by the model\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Compute custom loss with class weights for imbalanced data handling\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "\n",
    "def make_predictions(model, df):\n",
    "    \n",
    "\n",
    "    sentences = df.input.tolist()\n",
    "\n",
    "      # Define the batch size\n",
    "    batch_size = 32  # You can adjust this based on your system's memory capacity\n",
    "\n",
    "      # Initialize an empty list to store the model outputs\n",
    "    all_outputs = []\n",
    "\n",
    "      # Process the sentences in batches\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "          # Get the batch of sentences\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "\n",
    "          # Tokenize the batch\n",
    "        inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "          # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
    "        inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "\n",
    "          # Perform inference and store the logits\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            all_outputs.append(outputs['logits'])\n",
    "\n",
    "    final_outputs = torch.cat(all_outputs, dim=0)\n",
    "    df['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
    "    #df['predictions']=df['predictions'].apply(lambda l:category_map[l])\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_performance_metrics(df):\n",
    "    y_test = df.Institutional_Form_category\n",
    "    y_pred = df.predictions\n",
    "    print(f\"comparing test {y_test} and pred {y_pred}\")\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "def get_performance_metrics(df):\n",
    "    y_test = df.Institutional_Form_category\n",
    "    y_pred = df.predictions\n",
    "    print(f\"comparing test {y_test} and pred {y_pred}\")\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "# Define hyperparameter grid\n",
    "learning_rates = [1e-3]\n",
    "weight_decays = [0.1, 0.2]\n",
    "\n",
    "# Keep track of results\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for wd in weight_decays:\n",
    "        print(f\"\\nTraining with learning_rate={lr}, weight_decay={wd}\\n\")\n",
    "\n",
    "        # Update training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f'sequence_classification_lr{lr}_wd{wd}',\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=16,\n",
    "            num_train_epochs=3,\n",
    "            weight_decay=wd,\n",
    "            evaluation_strategy='epoch',\n",
    "            save_strategy='epoch',\n",
    "            load_best_model_at_end=True,\n",
    "            logging_dir=f'logs_lr{lr}_wd{wd}',\n",
    "            logging_steps=10\n",
    "        )\n",
    "\n",
    "        # Initialize trainer\n",
    "        trainer = CustomTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_datasets['train'],\n",
    "            eval_dataset=tokenized_datasets['val'],\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=collate_fn,\n",
    "            compute_metrics=compute_metrics,\n",
    "            class_weights=class_weights,\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        train_result = trainer.train()\n",
    "\n",
    "        # Record training loss and evaluation metrics\n",
    "        eval_metrics = trainer.evaluate()\n",
    "        train_loss = train_result.training_loss\n",
    "\n",
    "        # Make predictions and compute performance metrics\n",
    "        df_val = make_predictions(model, df_val)\n",
    "        performance_metrics = get_performance_metrics(df_val)\n",
    "\n",
    "        # Append the metrics to results\n",
    "        results.append({\n",
    "            \"learning_rate\": lr,\n",
    "            \"weight_decay\": wd,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"eval_metrics\": eval_metrics,\n",
    "            \"performance_metrics\": performance_metrics\n",
    "        })\n",
    "\n",
    "        # Print results for the current model\n",
    "        print(f\"Results for learning_rate={lr}, weight_decay={wd}\")\n",
    "        print(f\"Train Loss: {train_loss}\")\n",
    "        print(f\"Evaluation Metrics: {eval_metrics}\")\n",
    "        print(f\"Performance Metrics: {performance_metrics}\")\n",
    "\n",
    "# Summarize all results\n",
    "print(\"\\nSummary of all results:\")\n",
    "for res in results:\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b249e-75b1-4343-930e-4228a643f932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llama]",
   "language": "python",
   "name": "conda-env-llama-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
